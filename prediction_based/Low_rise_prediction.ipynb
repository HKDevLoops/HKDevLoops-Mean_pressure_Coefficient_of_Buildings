{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-15T19:34:45.814907Z",
     "start_time": "2025-03-15T19:34:45.476636Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Load and Preprocess Data ---\n",
    "def load_mat_data(root_folder):\n",
    "    all_data = []\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mat\"):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                mat_data = loadmat(file_path)\n",
    "                if 'wind_pressure' in mat_data and 'wind_angle' in mat_data:\n",
    "                    df = pd.DataFrame({\n",
    "                        'Wind_Pressure': mat_data['wind_pressure'].flatten(),\n",
    "                        'Wind_Angle': mat_data['wind_angle'].flatten(),\n",
    "                        'Building_Height_Ratio': mat_data['height_ratio'].flatten()\n",
    "                    })\n",
    "                    all_data.append(df)\n",
    "    combined_df = pd.concat(all_data).reset_index(drop=True)\n",
    "    return combined_df\n",
    "\n",
    "# Load data\n",
    "root_folder = 'D:\\\\CAPSTONE PROJECT\\\\data\\\\Low-rise with eaves\\\\roof type a\\\\height 1;4'\n",
    "df = load_mat_data(root_folder)\n",
    "\n",
    "features = df[['Wind_Angle', 'Building_Height_Ratio']]\n",
    "targets = df['Wind_Pressure']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define PINN Model\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(PINN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "input_dim = X_train.shape[1]\n",
    "model = PINN(input_dim, 128, 1).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert to Tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_pred_tensor = model(X_test_tensor).cpu().detach().numpy()\n",
    "y_pred = y_pred_tensor.flatten()\n",
    "\n",
    "ae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {ae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r', lw=2)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs. Predicted Wind Pressure\")\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(y_test - y_pred, bins=30, kde=True)\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "plt.title(\"Prediction Error Distribution\")\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 38\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Load data\u001B[39;00m\n\u001B[0;32m     37\u001B[0m root_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mCAPSTONE PROJECT\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mLow-rise with eaves\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mroof type a\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mheight 1;4\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 38\u001B[0m df \u001B[38;5;241m=\u001B[39m load_mat_data(root_folder)\n\u001B[0;32m     40\u001B[0m features \u001B[38;5;241m=\u001B[39m df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWind_Angle\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBuilding_Height_Ratio\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m     41\u001B[0m targets \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWind_Pressure\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "Cell \u001B[1;32mIn[7], line 33\u001B[0m, in \u001B[0;36mload_mat_data\u001B[1;34m(root_folder)\u001B[0m\n\u001B[0;32m     27\u001B[0m                 df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\n\u001B[0;32m     28\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWind_Pressure\u001B[39m\u001B[38;5;124m'\u001B[39m: mat_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwind_pressure\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mflatten(),\n\u001B[0;32m     29\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWind_Angle\u001B[39m\u001B[38;5;124m'\u001B[39m: mat_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwind_angle\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mflatten(),\n\u001B[0;32m     30\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBuilding_Height_Ratio\u001B[39m\u001B[38;5;124m'\u001B[39m: mat_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheight_ratio\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m     31\u001B[0m                 })\n\u001B[0;32m     32\u001B[0m                 all_data\u001B[38;5;241m.\u001B[39mappend(df)\n\u001B[1;32m---> 33\u001B[0m combined_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(all_data)\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m combined_df\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\CAPSTONE_PROJECT\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001B[0m, in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    380\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 382\u001B[0m op \u001B[38;5;241m=\u001B[39m _Concatenator(\n\u001B[0;32m    383\u001B[0m     objs,\n\u001B[0;32m    384\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[0;32m    385\u001B[0m     ignore_index\u001B[38;5;241m=\u001B[39mignore_index,\n\u001B[0;32m    386\u001B[0m     join\u001B[38;5;241m=\u001B[39mjoin,\n\u001B[0;32m    387\u001B[0m     keys\u001B[38;5;241m=\u001B[39mkeys,\n\u001B[0;32m    388\u001B[0m     levels\u001B[38;5;241m=\u001B[39mlevels,\n\u001B[0;32m    389\u001B[0m     names\u001B[38;5;241m=\u001B[39mnames,\n\u001B[0;32m    390\u001B[0m     verify_integrity\u001B[38;5;241m=\u001B[39mverify_integrity,\n\u001B[0;32m    391\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    392\u001B[0m     sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[0;32m    393\u001B[0m )\n\u001B[0;32m    395\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\CAPSTONE_PROJECT\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001B[0m, in \u001B[0;36m_Concatenator.__init__\u001B[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverify_integrity \u001B[38;5;241m=\u001B[39m verify_integrity\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy \u001B[38;5;241m=\u001B[39m copy\n\u001B[1;32m--> 445\u001B[0m objs, keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clean_keys_and_objs(objs, keys)\n\u001B[0;32m    447\u001B[0m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[0;32m    448\u001B[0m ndims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_ndims(objs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\CAPSTONE_PROJECT\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001B[0m, in \u001B[0;36m_Concatenator._clean_keys_and_objs\u001B[1;34m(self, objs, keys)\u001B[0m\n\u001B[0;32m    504\u001B[0m     objs_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(objs)\n\u001B[0;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(objs_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 507\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo objects to concatenate\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    509\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m keys \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    510\u001B[0m     objs_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(com\u001B[38;5;241m.\u001B[39mnot_none(\u001B[38;5;241m*\u001B[39mobjs_list))\n",
      "\u001B[1;31mValueError\u001B[0m: No objects to concatenate"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51f5dccdf0ec2d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "db05685ee5f4711"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
